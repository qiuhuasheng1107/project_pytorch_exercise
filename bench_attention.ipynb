{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bench_attention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM03NYTNmTKGpqgFrtFiXo7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qiuhuasheng1107/project_pytorch_exercise/blob/main/bench_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEhFTn-1b3dU",
        "outputId": "005fe57b-25cf-4b19-f0f0-738a8523c84b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f37331019b0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import random\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import random_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "from imblearn.over_sampling import RandomOverSampler \n",
        "from collections import Counter\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('deep_with_duration.csv')\n",
        "print(df.shape)\n",
        "print(df.columns.values)\n",
        "df = df[df['cb_list'].notna()]\n",
        "print('*******')\n",
        "print(\"size of data:\", len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2EWlZifb7HV",
        "outputId": "65791d07-c6ad-4ac6-9308-18137db82680"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(124853, 23)\n",
            "['cb_list' 'date_list' 'fst_hipday' 'age' 'sex' 'ALENDRONATE' 'CALCITONIN'\n",
            " 'CALCITONIN_I' 'DENOSUMAB' 'DENOSUMAB_C' 'ETIDRONATE' 'IBANDRONIC'\n",
            " 'PAMIDRONATE' 'RALOXIFENE' 'TERIPARATIDE' 'ZOLEDRONIC' 'ZOLEDRONIC_O'\n",
            " 'cindate' 'before_cb' 'before_date' 'psd_date' 'dur_list' 'class']\n",
            "*******\n",
            "size of data: 124853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label to index & y\n",
        "label_to_ix = {\"first_snd\": 0, \"first_die\": 1, \"good\": 2, \"snd_die\":3}\n",
        "\n",
        "y = []\n",
        "for i in range(0, len(df)):\n",
        "    lab = df.iloc[i, 22]\n",
        "    y.append(label_to_ix[lab])"
      ],
      "metadata": {
        "id": "ntS3kvwWca0m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cb to index\n",
        "cb_column = df[['before_cb']]\n",
        "cb_to_ix = {}\n",
        "\n",
        "for i in range(0, len(df)):\n",
        "    cbs = cb_column.iloc[i, 0].split(', ')\n",
        "    for cb in cbs:\n",
        "        if cb not in cb_to_ix:  # illness has not been assigned an index yet\n",
        "            cb_to_ix[cb] = len(cb_to_ix)\n",
        "print(cb_to_ix)\n",
        "print(len(cb_to_ix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghM5nlmgcfh8",
        "outputId": "6949b7b7-270f-4c12-dbeb-21c99dcf5c74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Glaucomadate': 0, 'Cataractdate': 1, 'Chronicplumonarydiseasedate': 2, 'Congestiveheartfailuredate': 3, 'DMwithoutcomplicationsdate': 4, 'Dementiadate': 5, 'Mildliverdiseasedate': 6, 'Malignantneoplasmsdate': 7, 'Pepticulcerdiseasedate': 8, 'Metastaticsolidtumordate': 9, 'Cerebrovasculardiseasedate': 10, 'Renaldiseasedate': 11, 'DMwithcomplicationsdate': 12, 'Rheumatologicdiseasedate': 13, 'Peripheralvasculardiseasedate': 14, 'Keratitisdate': 15, 'Myocardialinfarctiondate': 16, 'Mosliverdiseasedate': 17, 'Hemiparaplegiadate': 18, 'Cushingdate': 19, 'Thyrotoxicosisdate': 20, 'AgerelatedMDdate': 21, 'Hyperparathyroidismdate': 22, 'Pagetdate': 23, 'Aidsdate': 24}\n",
            "25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return idxs\n",
        "\n",
        "# padding the input and construct feature set\n",
        "X = []\n",
        "for i in range (0, len(cb_column)):\n",
        "    seq = cb_column.iloc[i, 0].split(', ')\n",
        "    res = prepare_sequence(seq, cb_to_ix)\n",
        "    X.append(res)\n",
        "print(X[0:5])\n",
        "\n",
        "X_lengths = []\n",
        "for i in range(0, len(cb_column)):\n",
        "    seq = cb_column.iloc[i, 0].split(', ')\n",
        "    seq_len = len(seq)\n",
        "    X_lengths.append(seq_len)\n",
        "\n",
        "longest_cbs = max(X_lengths)\n",
        "print(longest_cbs)\n",
        "rows = len(cb_column)\n",
        "padded_X = np.zeros((rows, longest_cbs))\n",
        "\n",
        "for i, x_len in enumerate(X_lengths):\n",
        "  sequence = X[i]\n",
        "  padded_X[i, longest_cbs-x_len:] = sequence[:x_len]\n",
        "print(padded_X[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoycYH5LciBj",
        "outputId": "7836ac38-35dd-48b8-d723-69c948b4939a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 2, 3, 4, 5], [2, 4], [6], [7, 8, 9, 6], [1]]\n",
            "16\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 3. 4. 5.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 4.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 7. 8. 9. 6.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct the rest feature set\n",
        "diag = df[['age', 'sex']]\n",
        "diag['sex'] = diag['sex'].map({'F': 1, 'M': 0})\n",
        "drug = df.loc[:, 'ALENDRONATE':'ZOLEDRONIC_O']\n",
        "features = pd.concat([diag, drug], axis=1)\n",
        "features = features.values.astype(float)\n",
        "print('feature:', features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h07Le8TDcmP1",
        "outputId": "a0ab0777-c1ba-4d7b-f16b-3e572d18db0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature: (124853, 14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct training, validation, and testing dataset\n",
        "x_train01, x_test01, y_train01, y_test01 = train_test_split(padded_X, y,test_size=0.1, random_state=42)\n",
        "x_train02, x_test02, y_train02, y_test02 = train_test_split(features, y,test_size=0.1, random_state=42)\n",
        "print(y_test01 == y_test02)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwH5pJy6c5Ll",
        "outputId": "5655f1f7-d379-4a32-9a28-2734dbd0d1da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "under_sampler = RandomOverSampler(random_state=0)\n",
        "x_train01_sp, y_train01_sp = under_sampler.fit_resample(x_train01, y_train01)\n",
        "x_train02_sp, y_train02_sp = under_sampler.fit_resample(x_train02, y_train02)\n",
        "print(y_train01_sp == y_train02_sp)\n",
        "Counter(y_train01_sp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Xj_dFidCGR",
        "outputId": "164a5c93-8797-47a3-c0f6-e6f8fde8cf58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 60849, 1: 60849, 2: 60849, 3: 60849})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input 1\n",
        "inputs_1 = torch.from_numpy(x_train01_sp).type(torch.int)\n",
        "targets_1 = torch.from_numpy(np.array(y_train01_sp)).type(torch.LongTensor)\n",
        "\n",
        "# input 2\n",
        "inputs_2 = torch.from_numpy(x_train02_sp).type(torch.float)\n",
        "targets_2 = torch.from_numpy(np.array(y_train02_sp)).type(torch.LongTensor)"
      ],
      "metadata": {
        "id": "WnP_fOVEdJT5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct training and validation dataset\n",
        "train_val = TensorDataset(inputs_1, inputs_2, targets_1)\n",
        "val_size = 6000\n",
        "train_size = len(train_val) - val_size"
      ],
      "metadata": {
        "id": "7pOMY6mGdMlv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds = random_split(train_val, [train_size, val_size])\n",
        "batch_size = 128\n",
        "train_dl = DataLoader(train_ds, batch_size)\n",
        "val_dl = DataLoader(val_ds, batch_size)"
      ],
      "metadata": {
        "id": "pLS2N1jjdPEt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing dataset\n",
        "inputs_t1 = torch.from_numpy(x_test01).type(torch.int)\n",
        "targets_t1 = torch.from_numpy(np.array(y_test01)).type(torch.LongTensor)\n",
        "\n",
        "inputs_t2 = torch.from_numpy(x_test02).type(torch.float)\n",
        "targets_t2 = torch.from_numpy(np.array(y_test02)).type(torch.LongTensor)\n",
        "\n",
        "test = TensorDataset(inputs_t1, inputs_t2, targets_t1)"
      ],
      "metadata": {
        "id": "IPSLTpFqdRkL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import linear\n",
        "# model construction\n",
        "class mymodel(nn.Module):\n",
        "    def __init__(self, embedding_dim, cbs_size, output): \n",
        "      super(mymodel, self).__init__()\n",
        "      self.cb_embeddings = nn.Embedding(cbs_size, embedding_dim)\n",
        "      self.att_ly = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=2, batch_first=True)\n",
        "      self.linear = nn.Linear(embedding_dim*16+14, output)\n",
        "\n",
        "    def forward(self, seq, fts, embedding_dim):\n",
        "      embeds = self.cb_embeddings(seq)\n",
        "      out,_ = self.att_ly(embeds, embeds, embeds)\n",
        "      out = torch.reshape(out, (out.shape[0], -1))\n",
        "      out = torch.cat((out, fts), dim=1)\n",
        "      out = self.linear(out)\n",
        "      return torch.log_softmax(out, dim=1)"
      ],
      "metadata": {
        "id": "0_mc3P78dUBz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 6\n",
        "model = mymodel(embedding_dim, len(cb_to_ix), len(label_to_ix))"
      ],
      "metadata": {
        "id": "b9bfvRN11zQ8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.NLLLoss()\n",
        "opt = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "163m8QjS3M7i"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "  _, preds = torch.max(outputs, dim=1)\n",
        "  return torch.sum(preds == labels).item()/len(preds)"
      ],
      "metadata": {
        "id": "5aeUjbao3PDx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_batch(model, loss_fn, x1, x2, yb, opt=None, metric=None):\n",
        "    preds = model(x1, x2, embedding_dim)\n",
        "    loss = loss_fn(preds, yb)\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    metric_result = None\n",
        "    if metric is not None:\n",
        "        metric_result = metric(preds, yb)\n",
        "    return loss.item(), len(x1), metric_result"
      ],
      "metadata": {
        "id": "RxHhR66-3RDs"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loss_fn, val_dl, metric=None):\n",
        "    with torch.no_grad():\n",
        "        results = [loss_batch(model, loss_fn, x1, x2, yb, metric=metric) for x1, x2, yb in val_dl]\n",
        "        losses, nums, metrics = zip(*results)\n",
        "        total = np.sum(nums)\n",
        "        avg_loss = np.sum(np.multiply(losses, nums))/total\n",
        "        avg_metric = None\n",
        "        if metric is not None:\n",
        "            avg_metric=np.sum(np.multiply(metrics, nums))/total\n",
        "    return avg_loss, total, avg_metric"
      ],
      "metadata": {
        "id": "Tvcnn94K3YMU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, total, acc = evaluate(model, loss_fn, val_dl, metric=accuracy)\n",
        "print(val_loss, total, acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME9YoYfX3dZy",
        "outputId": "73a767be-9746-42d2-992f-18ed2f6e2c65"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.258766297658284 6000 0.23783333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(epochs, model, loss_fn, opt, train_dl, val_dl, metric=None):\n",
        "    train_losses, val_losses, accs = [], [], []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for x1, x2, yb in train_dl:\n",
        "            train_loss, _,_ = loss_batch(model, loss_fn, x1, x2, yb, opt)\n",
        "        model.eval()\n",
        "        result = evaluate(model, loss_fn, val_dl, metric)\n",
        "        val_loss, total, val_metric = result\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        accs.append(val_metric)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(epoch + 1, epochs, val_loss, val_metric)\n",
        "    return train_losses, val_losses, accs"
      ],
      "metadata": {
        "id": "9TKLojN53fsv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses, accy = fit(10, model, loss_fn, opt, train_dl, val_dl, accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBtqU9zq3lRW",
        "outputId": "8bf59fc0-ebb2-4448-bf6a-d40ff9460cc4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 10 1.3218831599553427 0.3565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_x(x1, x2, model):\n",
        "  yb = model(x1, x2, 6)\n",
        "  _,preds = torch.max(yb, dim=1)\n",
        "  return preds.numpy()"
      ],
      "metadata": {
        "id": "5CeBv8wM3pcL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1, x2, label = test[:]\n",
        "print(label.numpy(), 'predicted', predict_x(x1, x2, model))\n",
        "y_pred = predict_x(x1, x2, model)\n",
        "print(classification_report(label, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEl7t8RdQjAi",
        "outputId": "fd16bcb7-c094-4417-fb2e-982a6e7193a2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 1 ... 1 1 2] predicted [2 0 2 ... 1 1 1]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.18      0.11       637\n",
            "           1       0.70      0.53      0.60      6809\n",
            "           2       0.51      0.48      0.49      4398\n",
            "           3       0.09      0.24      0.13       642\n",
            "\n",
            "    accuracy                           0.48     12486\n",
            "   macro avg       0.34      0.36      0.33     12486\n",
            "weighted avg       0.57      0.48      0.51     12486\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1yS2wPD_QpYV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}